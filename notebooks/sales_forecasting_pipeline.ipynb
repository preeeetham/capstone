{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Walmart Sales Forecasting System\n",
    "\n",
    "This notebook implements a comprehensive sales forecasting system based on research paper methodologies.\n",
    "\n",
    "## Overview\n",
    "- **Dataset**: Walmart Store Sales Forecasting (Kaggle)\n",
    "- **Goal**: Compare baseline models vs research-style models\n",
    "- **Evaluation**: RMSE, MAE, MAPE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('../')\n",
    "\n",
    "from src.data_loader import load_dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "train_df, test_df, features_df, stores_df = load_dataset()\n",
    "\n",
    "print(f\"\\nTrain dataset shape: {train_df.shape}\")\n",
    "print(f\"Test dataset shape: {test_df.shape}\")\n",
    "print(f\"\\nTrain columns: {list(train_df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.eda import generate_eda_report, check_missing_values, detect_outliers, plot_sales_trends\n",
    "\n",
    "# Generate comprehensive EDA report\n",
    "generate_eda_report(train_df, save_dir='../results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.feature_engineering import create_all_features, get_feature_columns\n",
    "\n",
    "# Create all features\n",
    "train_df_featured = create_all_features(\n",
    "    train_df.copy(),\n",
    "    target_col='Weekly_Sales',\n",
    "    lags=[1, 2, 4, 12],\n",
    "    rolling_windows=[4, 8, 12]\n",
    ")\n",
    "\n",
    "# Remove rows with NaN from lag features (first few rows)\n",
    "train_df_featured = train_df_featured.dropna(subset=['Weekly_Sales']).reset_index(drop=True)\n",
    "\n",
    "print(f\"\\nDataset shape after feature engineering: {train_df_featured.shape}\")\n",
    "print(f\"\\nFeature columns: {len(get_feature_columns(train_df_featured))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Time-Based Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import time_based_split\n",
    "\n",
    "# Split data by time\n",
    "train_data, val_data = time_based_split(train_df_featured, date_col='Date', train_ratio=0.8)\n",
    "\n",
    "# Prepare features for ML models\n",
    "from src.utils import prepare_ml_data\n",
    "from src.feature_engineering import get_feature_columns\n",
    "\n",
    "feature_cols = get_feature_columns(train_data)\n",
    "\n",
    "X_train, y_train = prepare_ml_data(train_data, feature_cols=feature_cols)\n",
    "X_val, y_val = prepare_ml_data(val_data, feature_cols=feature_cols)\n",
    "\n",
    "print(f\"\\nTraining features shape: {X_train.shape}\")\n",
    "print(f\"Validation features shape: {X_val.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import NaiveForecast, MovingAverage\n",
    "from src.evaluation import evaluate_model\n",
    "\n",
    "# Naive Forecast\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Training Baseline Models\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "naive_model = NaiveForecast()\n",
    "naive_model.fit(train_data, target_col='Weekly_Sales')\n",
    "naive_pred = naive_model.predict(val_data)\n",
    "naive_results = evaluate_model(y_val, naive_pred, \"Naive Forecast\")\n",
    "print(f\"\\nNaive Forecast - RMSE: {naive_results['RMSE']:.2f}, MAE: {naive_results['MAE']:.2f}, MAPE: {naive_results['MAPE']:.2f}%\")\n",
    "\n",
    "# Moving Average\n",
    "ma_model = MovingAverage(window=4)\n",
    "ma_model.fit(train_data, target_col='Weekly_Sales')\n",
    "ma_pred = ma_model.predict(val_data)\n",
    "ma_results = evaluate_model(y_val, ma_pred, \"Moving Average (4 weeks)\")\n",
    "print(f\"Moving Average - RMSE: {ma_results['RMSE']:.2f}, MAE: {ma_results['MAE']:.2f}, MAPE: {ma_results['MAPE']:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Research-Style Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Statistical Model: SARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import SARIMAModel\n",
    "\n",
    "# Note: SARIMA can be slow for many time series\n",
    "# We'll use a sample for demonstration\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Training SARIMA Model\")\n",
    "print(\"=\"*60)\n",
    "print(\"Note: This may take a while. Using sample data for speed...\")\n",
    "\n",
    "# Use sample stores/depts for faster training\n",
    "sample_stores = train_data['Store'].unique()[:5]  # Use first 5 stores\n",
    "sample_train = train_data[train_data['Store'].isin(sample_stores)].copy()\n",
    "sample_val = val_data[val_data['Store'].isin(sample_stores)].copy()\n",
    "\n",
    "sarima_model = SARIMAModel(order=(1, 1, 1), seasonal_order=(1, 1, 1, 52))\n",
    "sarima_model.fit(sample_train, target_col='Weekly_Sales')\n",
    "sarima_pred = sarima_model.predict(sample_val)\n",
    "\n",
    "if len(sample_val) > 0:\n",
    "    sarima_y_val = sample_val['Weekly_Sales'].values\n",
    "    sarima_results = evaluate_model(sarima_y_val, sarima_pred, \"SARIMA\")\n",
    "    print(f\"\\nSARIMA - RMSE: {sarima_results['RMSE']:.2f}, MAE: {sarima_results['MAE']:.2f}, MAPE: {sarima_results['MAPE']:.2f}%\")\n",
    "else:\n",
    "    sarima_results = {'Model': 'SARIMA', 'RMSE': np.inf, 'MAE': np.inf, 'MAPE': np.inf}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Statistical Model: Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import ProphetModel\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Training Prophet Model\")\n",
    "print(\"=\"*60)\n",
    "print(\"Note: This may take a while. Using sample data for speed...\")\n",
    "\n",
    "# Use same sample for consistency\n",
    "prophet_model = ProphetModel(yearly_seasonality=True, weekly_seasonality=True)\n",
    "prophet_model.fit(sample_train, target_col='Weekly_Sales', date_col='Date')\n",
    "prophet_pred = prophet_model.predict(sample_val, date_col='Date')\n",
    "\n",
    "if len(sample_val) > 0:\n",
    "    prophet_y_val = sample_val['Weekly_Sales'].values\n",
    "    prophet_results = evaluate_model(prophet_y_val, prophet_pred, \"Prophet\")\n",
    "    print(f\"\\nProphet - RMSE: {prophet_results['RMSE']:.2f}, MAE: {prophet_results['MAE']:.2f}, MAPE: {prophet_results['MAPE']:.2f}%\")\n",
    "else:\n",
    "    prophet_results = {'Model': 'Prophet', 'RMSE': np.inf, 'MAE': np.inf, 'MAPE': np.inf}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Machine Learning Model: LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import LightGBMModel\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Training LightGBM Model\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "lgb_model = LightGBMModel()\n",
    "lgb_model.fit(X_train, y_train, X_val, y_val)\n",
    "lgb_pred = lgb_model.predict(X_val)\n",
    "lgb_results = evaluate_model(y_val, lgb_pred, \"LightGBM\")\n",
    "print(f\"\\nLightGBM - RMSE: {lgb_results['RMSE']:.2f}, MAE: {lgb_results['MAE']:.2f}, MAPE: {lgb_results['MAPE']:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Machine Learning Model: XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import XGBoostModel\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Training XGBoost Model\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "xgb_model = XGBoostModel()\n",
    "xgb_model.fit(X_train, y_train, X_val, y_val)\n",
    "xgb_pred = xgb_model.predict(X_val)\n",
    "xgb_results = evaluate_model(y_val, xgb_pred, \"XGBoost\")\n",
    "print(f\"\\nXGBoost - RMSE: {xgb_results['RMSE']:.2f}, MAE: {xgb_results['MAE']:.2f}, MAPE: {xgb_results['MAPE']:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 Deep Learning Model: LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import LSTMModel\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Training LSTM Model\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# LSTM requires special handling\n",
    "lstm_model = LSTMModel(sequence_length=12, units=50, epochs=20, batch_size=32)\n",
    "lstm_model.fit(train_data, target_col='Weekly_Sales', feature_cols=feature_cols)\n",
    "lstm_pred = lstm_model.predict(val_data, feature_cols=feature_cols)\n",
    "lstm_results = evaluate_model(y_val, lstm_pred, \"LSTM\")\n",
    "print(f\"\\nLSTM - RMSE: {lstm_results['RMSE']:.2f}, MAE: {lstm_results['MAE']:.2f}, MAPE: {lstm_results['MAPE']:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.evaluation import compare_models, plot_predictions, plot_all_predictions\n",
    "\n",
    "# Collect all results\n",
    "all_results = [\n",
    "    naive_results,\n",
    "    ma_results,\n",
    "    sarima_results,\n",
    "    prophet_results,\n",
    "    lgb_results,\n",
    "    xgb_results,\n",
    "    lstm_results\n",
    "]\n",
    "\n",
    "# Compare models\n",
    "comparison_df = compare_models(all_results, save_path='../results/model_comparison.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions for all models\n",
    "predictions_dict = {\n",
    "    'Naive Forecast': {'y_true': y_val, 'y_pred': naive_pred},\n",
    "    'Moving Average': {'y_true': y_val, 'y_pred': ma_pred},\n",
    "    'LightGBM': {'y_true': y_val, 'y_pred': lgb_pred},\n",
    "    'XGBoost': {'y_true': y_val, 'y_pred': xgb_pred}\n",
    "}\n",
    "\n",
    "# Add SARIMA and Prophet if available\n",
    "if len(sample_val) > 0:\n",
    "    predictions_dict['SARIMA'] = {'y_true': sarima_y_val, 'y_pred': sarima_pred}\n",
    "    predictions_dict['Prophet'] = {'y_true': prophet_y_val, 'y_pred': prophet_pred}\n",
    "\n",
    "plot_all_predictions(predictions_dict, save_path='../results/all_predictions.png')\n",
    "\n",
    "# Individual plots for top models\n",
    "plot_predictions(y_val, lgb_pred, 'LightGBM', save_path='../results/lightgbm_predictions.png')\n",
    "plot_predictions(y_val, xgb_pred, 'XGBoost', save_path='../results/xgboost_predictions.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The forecasting pipeline has been completed. All results are saved in the `results/` directory."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
